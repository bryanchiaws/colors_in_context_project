{"cells":[{"cell_type":"markdown","metadata":{"id":"fb0pJ2MGCj6E"},"source":["# Homework and bake-off: pragmatic color descriptions"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"G3gT5jtQCj6F","colab":{"base_uri":"https://localhost:8080/"},"outputId":"37c37cca-e29a-49d5-90a8-62e895196c67","executionInfo":{"status":"ok","timestamp":1654408100138,"user_tz":420,"elapsed":1166,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/MyDrive/cs224u\n"]}],"source":["__author__ = \"Christopher Potts\"\n","__version__ = \"CS224u, Stanford, Summer 2022\"\n","\n","import os\n","\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","    # This mounts your Google Drive to the Colab VM.\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","\n","    # TODO: Enter the foldername in your Drive where you have saved the unzipped\n","    FOLDERNAME = 'MyDrive/cs224u'\n","    assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","    # Now that we've mounted your Drive, this ensures that\n","    # the Python interpreter of the Colab VM can load\n","    # python files from within it.\n","    import sys\n","    sys.path.append('/content/gdrive/{}'.format(FOLDERNAME))\n","\n","    %cd /content/gdrive/$FOLDERNAME"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"sY_Uv_I6Cj6I","executionInfo":{"status":"ok","timestamp":1654408108801,"user_tz":420,"elapsed":8665,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["from colors import ColorsCorpusReader\n","from nltk.translate.bleu_score import corpus_bleu\n","import numpy as np\n","import os\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from torch_color_describer import ContextualColorDescriber\n","from torch_color_describer import create_example_dataset\n","\n","import utils\n","from utils import START_SYMBOL, END_SYMBOL, UNK_SYMBOL"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3zcDD717Cj6I","executionInfo":{"status":"ok","timestamp":1654408109331,"user_tz":420,"elapsed":533,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["utils.fix_random_seeds()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"2itTM_5tCj6I","executionInfo":{"status":"ok","timestamp":1654408109332,"user_tz":420,"elapsed":5,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["COLORS_SRC_FILENAME = os.path.join(\n","    \"data\", \"colors\", \"filteredCorpus.csv\")"]},{"cell_type":"markdown","metadata":{"id":"5IkQF-gsCj6I"},"source":["## All two-word examples as a dev corpus\n","\n","So that you don't have to sit through excessively long training runs during development, I suggest working with the two-word-only subset of the corpus until you enter into the late stages of system testing."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"fcuRHppcCj6I","executionInfo":{"status":"ok","timestamp":1654408109332,"user_tz":420,"elapsed":5,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["dev_corpus = ColorsCorpusReader(\n","    COLORS_SRC_FILENAME,\n","    #word_count=2,\n","    normalize_colors=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"c8UGMbyqCj6J","executionInfo":{"status":"ok","timestamp":1654408113038,"user_tz":420,"elapsed":3710,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["dev_examples = list(dev_corpus.read())"]},{"cell_type":"markdown","metadata":{"id":"JNswLQh5Cj6J"},"source":["This subset has about one-third the examples of the full corpus:"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"GIxDLNEvCj6J","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0db1cbcb-d1de-4f4b-9615-3d71dbae6e51","executionInfo":{"status":"ok","timestamp":1654408113039,"user_tz":420,"elapsed":16,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["46994"]},"metadata":{},"execution_count":7}],"source":["len(dev_examples)"]},{"cell_type":"markdown","metadata":{"id":"yqdevKs7Cj6K"},"source":["We __should__ worry that it's not a fully representative sample. Most of the descriptions in the full corpus are shorter, and a large proportion are longer. So this dataset is mainly for debugging, development, and general hill-climbing. All findings should be validated on the full dataset at some point."]},{"cell_type":"markdown","metadata":{"id":"pVho4Xr-Cj6K"},"source":["## Dev dataset\n","\n","The first step is to extract the raw color and raw texts from the corpus:"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"_OybxaXjCj6K","executionInfo":{"status":"ok","timestamp":1654408113039,"user_tz":420,"elapsed":14,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["dev_rawcols, dev_texts = zip(*[[ex.colors, ex.contents] for ex in dev_examples])"]},{"cell_type":"code","source":["next(dev_corpus.read()).display()"],"metadata":{"id":"LWRmZSzWy3aI","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"1bd2d498-03d1-4ec3-f157-4d9a68ed26f5","executionInfo":{"status":"ok","timestamp":1654408114386,"user_tz":420,"elapsed":1360,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["The darker blue one\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 216x72 with 3 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABLElEQVR4nO3YsU3DUBRAUX+UCiqoyApMQsesdJmEFUgFFbSfBVBwYcnK5ZzWLt6Trp4sjznnAiU3ew8AWxM1OaImR9TkiJqcw6WHrw+fV/9r5OXjfqx57+nu++p3XZZlefu6/XPfMUZi1znnr7u61OSImhxRk3Pxm5r/4fH5fe8RVjmfjqvec6nJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRk3PYewD2dz4d9x5hUy41OaImR9TkjDnn3jPAplxqckRNjqjJETU5oiZH1OT8AK1HF0DPcEkgAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"T9Wyu_F0Cj6K"},"source":["The raw color representations are suitable inputs to a model, but the texts are just strings, so they can't really be processed as-is. Question 1 asks you to do some tokenizing!"]},{"cell_type":"markdown","metadata":{"id":"nyl63zoxCj6K"},"source":["## Random train–test split for development\n","\n","For the sake of development runs, we create a random train–test split:"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"0guYHY5QCj6K","executionInfo":{"status":"ok","timestamp":1654408114386,"user_tz":420,"elapsed":8,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["#dev_rawcols_train, dev_rawcols_test, dev_texts_train, dev_texts_test = \\\n","#    train_test_split(dev_rawcols, dev_texts)\n","\n","#dev_rawcols_test, dev_rawcols_train = dev_rawcols[:3473], dev_rawcols[3473:]\n","#dev_texts_test, dev_texts_train = dev_texts[:3473], dev_texts[3473:]\n","\n","dev_rawcols_train = dev_rawcols\n","dev_texts_train = dev_texts"]},{"cell_type":"markdown","metadata":{"id":"tAmU-R7ICj6L"},"source":["## Question 1: Improve the tokenizer [1 point]\n","\n","This is the first required question – the first required modification to the default pipeline.\n","\n","The function `tokenize_example` simply splits its string on whitespace and adds the required start and end symbols:"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"029l1cOECj6L","executionInfo":{"status":"ok","timestamp":1654408114387,"user_tz":420,"elapsed":8,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["def tokenize_example(s, vocab = None):\n","    import string\n","    import re\n","    \n","    endings = [\"er\", \"est\", \"ish\"]\n","\n","    s = s.lower()\n","    r = re.compile(r'[\\s{}]+'.format(re.escape(string.punctuation)))\n","    words = r.split(s)\n","    split = []\n","    \n","    for w in words:\n","        if w[-2:] == \"er\":\n","            w = w[:-2]\n","        elif w[-3:] == \"est\" or w[-3:] == \"ish\":\n","            w = w[:-3]\n","\n","        if vocab is not None:\n","            if w not in vocab:\n","                w = w.replace(w, '$UNK')\n","\n","        if w != '':\n","            split.append(w)\n","        \n","    return [START_SYMBOL] + split + [END_SYMBOL]"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"EsDKPDaJCj6L","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b1f25197-1182-4aa6-9a9e-3441f9b32983","executionInfo":{"status":"ok","timestamp":1654408114387,"user_tz":420,"elapsed":7,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<s>', 'brown', '</s>']"]},"metadata":{},"execution_count":12}],"source":["tokenize_example(dev_texts_train[386])"]},{"cell_type":"markdown","metadata":{"id":"mgTDfgIPCj6L"},"source":["__Your task__: Modify `tokenize_example` so that it does something more sophisticated with the input text. \n","\n","__Notes__:\n","\n","* There are useful ideas for this in [Monroe et al. 2017](https://transacl.org/ojs/index.php/tacl/article/view/1142)\n","* There is no requirement that you do word-level tokenization. Sub-word and multi-word are options.\n","* This question can interact with the size of your vocabulary (see just below), and in turn with decisions about how to use `UNK_SYMBOL`.\n","\n","__Important__: don't forget to add the start and end symbols, else the resulting models will definitely be terrible! The following test will check that your tokenizer has this property:"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"VoEbK7WECj6L","executionInfo":{"status":"ok","timestamp":1654408114388,"user_tz":420,"elapsed":7,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["def test_tokenize_example(func):\n","    s = \"A test string\"\n","    result = func(s)\n","    assert all(isinstance(tok, str) for tok in result), \\\n","        \"The tokenizer must return a list of strings.\"\n","    assert result[0] == START_SYMBOL, \\\n","        \"The tokenizer must add START_SYMBOL as the first token.\"\n","    assert result[-1] == END_SYMBOL, \\\n","        \"The tokenizer must add END_SYMBOL as the final token.\""]},{"cell_type":"code","execution_count":14,"metadata":{"id":"swbG8-O_Cj6M","executionInfo":{"status":"ok","timestamp":1654408114625,"user_tz":420,"elapsed":243,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["dev_seqs_train = [tokenize_example(s) for s in dev_texts_train]\n","\n","#dev_seqs_test = [tokenize_example(s) for s in dev_texts_test]"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"mL40lDpBCj6M","executionInfo":{"status":"ok","timestamp":1654408114625,"user_tz":420,"elapsed":4,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["#Standard dev_vocab method\n","dev_vocab = sorted({w for toks in dev_seqs_train for w in toks})\n","\n","#Remove words that only appear once\n","#from collections import Counter\n","#count_dict = Counter([w for toks in dev_seqs_train for w in toks])\n","#dev_vocab = sorted({tok for tok, count in count_dict.items() if count > 1})\n","\n","#Replace all words that only appear once in training set with UNK_SYMBOL\n","#dev_seqs_train = [tokenize_example(s, dev_vocab) for s in dev_texts_train]\n","\n","dev_vocab += [UNK_SYMBOL]"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"2URP5uZQCj6N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5150f2b3-3b9b-4b0f-a805-383725f30c84","executionInfo":{"status":"ok","timestamp":1654408114626,"user_tz":420,"elapsed":4,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2941"]},"metadata":{},"execution_count":16}],"source":["len(dev_vocab)"]},{"cell_type":"markdown","metadata":{"id":"3x_RWUaCCj6N"},"source":["## Question 2: Improve the color representations [1 point]\n","\n","This is the second required pipeline improvement for the assignment. \n","\n","The following functions do nothing at all to the raw input colors we get from the corpus. "]},{"cell_type":"code","source":["from vectorizers import FourierVectorizer"],"metadata":{"id":"LftPTT8Q0TSD","executionInfo":{"status":"ok","timestamp":1654408116482,"user_tz":420,"elapsed":1859,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","execution_count":18,"metadata":{"id":"NcPiqa4iCj6O","executionInfo":{"status":"ok","timestamp":1654408116482,"user_tz":420,"elapsed":3,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["def represent_color_context(colors):\n","\n","    return [represent_color(color) for color in colors]\n","\n","def represent_color(color):\n","    from itertools import product\n","    \n","    color0 = color[0]\n","    color1 = color[1]\n","    color2 = color[2]\n","    \n","    h = color0 \n","    v = color1 + color2 * min(color1, 1 - color1)\n","    if v == 0:\n","        s = 0\n","    else:\n","        s = 2 * (1 - color1 / v)\n","    color_rep = np.zeros((3, 3, 3, 2))\n","\n","    for j, k, l in product((0, 1, 2), repeat=3):    \n","        f_hat = np.exp(-2 * np.pi * complex(0, (j * h + k * s + l * v)))\n","        color_rep[j, k, l, 0] = f_hat.real\n","        color_rep[j, k, l, 1] = f_hat.imag\n","    \n","    return color_rep.transpose(3, 0, 1, 2).flatten().tolist()"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"r-1uzMzUCj6O","executionInfo":{"status":"ok","timestamp":1654408131668,"user_tz":420,"elapsed":15189,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["dev_cols_train = [represent_color_context(colors) for colors in dev_rawcols_train]\n","\n","#dev_cols_test = [represent_color_context(colors) for colors in dev_rawcols_test]"]},{"cell_type":"code","source":["GLOVE_HOME = os.path.join('data', 'glove.6B')\n","\n","def create_glove_embedding(vocab, glove_base_filename='glove.6B.50d.txt'):\n","    # Use `utils.glove2dict` to read in the GloVe file:\n","\n","    data = utils.glove2dict(os.path.join(GLOVE_HOME, glove_base_filename))\n","\n","    embedding, vocab = utils.create_pretrained_embedding(data, vocab)\n","\n","    return embedding, vocab\n","\n","dev_glove_embedding, dev_glove_vocab = create_glove_embedding(dev_vocab)\n","print(dev_glove_embedding.shape)\n","print(dev_glove_vocab)"],"metadata":{"id":"0vLClTUNVPFF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b765ccec-5ccb-4732-dda2-a94f53e96d02","executionInfo":{"status":"ok","timestamp":1654408137811,"user_tz":420,"elapsed":6156,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["(2941, 50)\n","['0', '1', '10', '13', '14', '15', '2', '20', '2012', '2nd', '3', '30', '30s', '3rd', '4', '40', '49', '50', '6', '7', '80', '80s', '</s>', '<s>', 'a', 'aaagh', 'able', 'about', 'abright', 'absence', 'accurate', 'ack', 'acronynyms', 'actual', 'actually', 'add', 'added', 'address', 'advancing', 'aft', 'again', 'ago', 'agree', 'agreed', 'ah', 'ahah', 'ahaha', 'ahahha', 'ahh', 'ahhh', 'ahhhh', 'ahint', 'ain', 'air', 'airline', 'airport', 'aka', 'album', 'alike', 'alittle', 'alive', 'all', 'allowed', 'almost', 'almosy', 'almsot', 'alomst', 'aloud', 'alright', 'also', 'although', 'always', 'am', 'amazing', 'american', 'amethyst', 'among', 'amost', 'amount', 'an', 'and', 'angry', 'anoth', 'answ', 'any', 'anymore', 'anyone', 'anything', 'anytime', 'anyway', 'anyways', 'apologize', 'apparel', 'appear', 'appears', 'appicane', 'applciane', 'apple', 'apples', 'appliance', 'applicance', 'apply', 'apposed', 'appreciate', 'aqua', 'aquamarine', 'aquarium', 'aquas', 'arange', 'are', 'aren', 'arent', 'aretha', 'arg', 'argh', 'arghghh', 'arghhhhhhhhhhhhhhhh', 'argue', 'army', 'around', 'art', 'artist', 'as', 'ash', 'ashy', 'ask', 'asphalt', 'assaulting', 'assist', 'associated', 'assume', 'astel', 'at', 'athe', 'atleast', 'attention', 'aua', 'auqa', 'autumn', 'avacado', 'available', 'avocado', 'avocados', 'aw', 'awareness', 'away', 'aweome', 'awesome', 'awful', 'awhile', 'awkward', 'awua', 'awwww', 'azure', 'b', 'babby', 'baby', 'babyfood', 'back', 'bad', 'bag', 'baige', 'ball', 'ballet', 'bam', 'banana', 'baney', 'barbie', 'barely', 'barf', 'bark', 'barn', 'barney', 'barneys', 'barni', 'barnie', 'barny', 'barnys', 'based', 'basic', 'basically', 'basketball', 'battleship', 'bblue', 'bbright', 'be', 'beach', 'bear', 'beautiful', 'because', 'bed', 'bee', 'been', 'before', 'begin', 'beginning', 'beige', 'beigey', 'beigh', 'beigy', 'being', 'believe', 'berries', 'berry', 'bett', 'between', 'bfight', 'biege', 'big', 'bigg', 'biggie', 'bight', 'biking', 'bin', 'bingo', 'bird', 'birght', 'birhg', 'birhgt', 'birte', 'bismol', 'bit', 'bkue', 'bkye', 'bl', 'black', 'blah', 'blame', 'bland', 'blank', 'blazing', 'ble', 'blend', 'blended', 'bleu', 'blie', 'blind', 'bliue', 'bllue', 'block', 'blood', 'blu', 'blue', 'bluebonnet', 'blueeee', 'bluegreen', 'bluegrey', 'bluegrren', 'bluei', 'blueiosh', 'blueis', 'blueist', 'blues', 'blueset', 'bluesh', 'bluesih', 'bluesist', 'blueste', 'bluey', 'blui', 'bluie', 'blund', 'bluosh', 'blur', 'blurdt', 'blurple', 'blush', 'blusih', 'bluw', 'bly', 'blye', 'blyue', 'boat', 'bodied', 'bog', 'bold', 'bonus', 'boo', 'boog', 'boogies', 'book', 'boone', 'bordering', 'boring', 'bornw', 'borwn', 'bot', 'both', 'bothr', 'bout', 'bown', 'box', 'boxes', 'boy', 'boys', 'brain', 'braindead', 'branch', 'brand', 'brat', 'bravo', 'bread', 'breakfast', 'breast', 'breight', 'brick', 'bricks', 'bridesmaid', 'brigeth', 'brigh', 'brighet', 'brighht', 'brighly', 'brighness', 'bright', 'bright5', 'brighte', 'brightened', 'brightere', 'brighteset', 'brightess', 'brightet', 'brighti', 'brightness', 'brightnesses', 'brightp', 'brightre', 'brightt', 'brighttttt', 'brigt', 'brigth', 'brihgt', 'briht', 'brisht', 'brit', 'brite', 'brith', 'briwn', 'brlue', 'brn', 'bro', 'broen', 'broiwn', 'bron', 'bronw', 'bronze', 'brothers', 'brow', 'browin', 'browinsh', 'brown', 'browned', 'brownie', 'browning', 'brownis', 'browns', 'brownsih', 'browny', 'brows', 'brright', 'brt', 'brught', 'bruight', 'bruise', 'brwn', 'brwon', 'btw', 'bu', 'bubblegum', 'bucks', 'buddy', 'bue', 'bueb', 'buel', 'bule', 'bull', 'bulls', 'bumm', 'bunch', 'burgandy', 'burgundy', 'burnt', 'bus', 'bush', 'bustin', 'but', 'butnot', 'button', 'bvblue', 'by', 'bye', 'c', 'caca', 'cadet', 'cadillac', 'cadillacs', 'cahrt', 'calibrated', 'calibration', 'call', 'called', 'calling', 'calm', 'came', 'camo', 'camoflage', 'camoflauge', 'can', 'canary', 'canc', 'cancel', 'candy', 'cant', 'cantelope', 'canvas', 'cape', 'cardboard', 'cardbord', 'care', 'careful', 'caribbean', 'carmel', 'carnations', 'carolina', 'carpet', 'carrot', 'cast', 'cat', 'catch', 'categorize', 'caught', 'cauliflow', 'cauliflower', 'cause', 'ceedj', 'cement', 'cent', 'certain', 'cerulean', 'cgrey', 'chalk', 'chameleon', 'champagne', 'chance', 'charcoal', 'chart', 'chartreus', 'chartreuse', 'chartruese', 'chartruse', 'chat', 'cheating', 'checkrobe', 'cheeks', 'cheeri', 'cheerios', 'cheers', 'cheese', 'cherry', 'chicago', 'chick', 'chiminea', 'chip', 'chocolate', 'choice', 'choose', 'chose', 'christmas', 'citrus', 'civil', 'cj', 'clash', 'class', 'classic', 'clay', 'clcik', 'clear', 'clearly', 'clemson', 'cleveland', 'click', 'clicked', 'clickon', 'clo', 'cloests', 'clored', 'clos', 'close', 'closeist', 'closes', 'closet', 'closetst', 'clost', 'clothes', 'clothing', 'cloths', 'cloud', 'cloudless', 'clouds', 'cloudy', 'clue', 'clues', 'cobalt', 'coclor', 'cocoa', 'code', 'coffe', 'coffee', 'cold', 'collor', 'coloe', 'cologe', 'color', 'colorblind', 'colored', 'colorful', 'colorless', 'colors', 'colorwise', 'colour', 'coloured', 'colow', 'colr', 'combination', 'combined', 'combo', 'come', 'comes', 'comfortable', 'comments', 'common', 'commonly', 'company', 'compared', 'complete', 'completely', 'computers', 'concord', 'concrete', 'cone', 'confederate', 'congrats', 'considered', 'construction', 'contacting', 'contain', 'cookie', 'cool', 'coor', 'copp', 'coral', 'corn', 'cornflow', 'correct', 'cotta', 'could', 'couldnt', 'count', 'counted', 'couple', 'crab', 'crap', 'crappp', 'crat', 'crayola', 'crayon', 'crayons', 'crazy', 'cream', 'creami', 'crem', 'creme', 'crikey', 'crimson', 'crisp', 'cross', 'crosses', 'cruel', 'cubs', 'cuz', 'cyan', 'cyans', 'd', 'da', 'dadull', 'dafflodils', 'daffodil', 'dak', 'dakr', 'dam', 'damn', 'damned', 'dandelion', 'dang', 'dangerous', 'dangit', 'dar', 'darblue', 'darg', 'dark', 'darkblue', 'darke', 'darker', 'darkerst', 'darket', 'darkewr', 'darkis', 'darkness', 'darkr', 'darl', 'darn', 'darof', 'darts', 'dary', 'dash', 'daught', 'day', 'days', 'dcale', 'ddark', 'dead', 'deal', 'deep', 'deepist', 'deere', 'def', 'definately', 'define', 'defined', 'definitely', 'defy', 'dell', 'denim', 'desaturated', 'descibe', 'descibing', 'describe', 'described', 'describing', 'descript', 'description', 'descriptions', 'descriptive', 'desert', 'di', 'diareah', 'diarrah', 'did', 'didn', 'didnt', 'died', 'diff', 'diffeeent', 'difference', 'differences', 'differenmt', 'different', 'differently', 'differnet', 'difficult', 'dijon', 'dill', 'diluted', 'dim', 'dimm', 'dimmed', 'dingi', 'dingy', 'dingyist', 'dino', 'dinosaur', 'dinosaure', 'dinosour', 'directions', 'dirt', 'dirti', 'dirty', 'discern', 'displays', 'distinct', 'distinctively', 'diull', 'dk', 'dlll', 'do', 'dodgers', 'does', 'doesn', 'doesnt', 'dog', 'doh', 'doin', 'doing', 'dokie', 'dole', 'dolphin', 'dolphins', 'don', 'done', 'dont', 'doodoo', 'dooo', 'door', 'down', 'dr', 'drab', 'drabb', 'drabi', 'dragg', 'drak', 'dreary', 'dress', 'drink', 'drinking', 'drk', 'drops', 'drrk', 'drunk', 'dry', 'dsmr', 'dsrk', 'duck', 'dude', 'duke', 'dul', 'dule', 'dulelst', 'dull', 'dulled', 'dullezt', 'dullist', 'dumb', 'dunno', 'during', 'dusk', 'duski', 'dusky', 'dusti', 'dusty', 'e', 'each', 'eal', 'eally', 'earil', 'earli', 'earth', 'earthi', 'earthtone', 'earthy', 'east', 'easy', 'eat', 'ed', 'eeek', 'eek', 'eesh', 'eeyore', 'egg', 'eggplant', 'eggs', 'eggshell', 'eh', 'ehh', 'eith', 'electric', 'elephant', 'eletric', 'eliminate', 'eliminating', 'elvis', 'em', 'emerald', 'end', 'ends', 'engine', 'enjoy', 'enjoyed', 'enjoying', 'enough', 'entrails', 'envy', 'eque', 'erange', 'eras', 'erasers', 'err', 'esque', 'essentially', 'etc', 'ev', 'even', 'evening', 'everything', 'everywhere', 'ew', 'exaclty', 'exact', 'exactly', 'example', 'excellent', 'exists', 'exit', 'expected', 'expensive', 'expert', 'expired', 'explain', 'explained', 'explor', 'explosion', 'ey', 'eye', 'eyes', 'ez', 'ezpz', 'f', 'face', 'faded', 'fading', 'failing', 'faint', 'faintly', 'fair', 'faiult', 'fake', 'fall', 'falls', 'familiar', 'family', 'fammily', 'famous', 'fan', 'far', 'fark', 'farth', 'fascia', 'fast', 'fatigues', 'fault', 'favorite', 'fawn', 'feedback', 'feel', 'feelin', 'feeling', 'feels', 'female', 'feminine', 'fern', 'few', 'ffs', 'fhe', 'field', 'fields', 'fiery', 'fin', 'find', 'fine', 'fingers', 'finished', 'fir', 'fire', 'firetruck', 'first', 'fit', 'five', 'flag', 'flamingo', 'flashi', 'flashy', 'flat', 'flatt', 'flavor', 'flavoring', 'fleash', 'flesh', 'fleshy', 'flor', 'flores', 'florescent', 'florida', 'flors', 'flourescent', 'flow', 'flowers', 'flowery', 'fluorescent', 'fluorescnet', 'foam', 'foamy', 'focusing', 'food', 'football', 'for', 'forget', 'form', 'forr', 'forte', 'forum', 'found', 'foundation', 'fragrance', 'fragrence', 'franklin', 'freaked', 'freakin', 'freaking', 'free', 'freen', 'freeze', 'freezing', 'fresh', 'frey', 'friend', 'frog', 'frogs', 'from', 'frue', 'fruit', 'fuchia', 'fuchsia', 'fuck', 'fucschia', 'fucsha', 'fuesha', 'full', 'fully', 'fun', 'funny', 'furth', 'fuschia', 'fuscia', 'fushia', 'fusia', 'fuzzy', 'g', 'game', 'games', 'garay', 'garb', 'garden', 'gark', 'gases', 'gatorade', 'gay', 'geeez', 'geen', 'geez', 'gem', 'general', 'generic', 'georgia', 'gery', 'get', 'gettin', 'getting', 'gey', 'geyist', 'gfreen', 'gg', 'ghrren', 'girl', 'girlie', 'girls', 'girly', 'give', 'given', 'giving', 'gj', 'gjgjgjg', 'glad', 'glitchy', 'gloomy', 'glossi', 'glow', 'glowing', 'glue', 'go', 'god', 'goes', 'goinf', 'going', 'gold', 'golden', 'goldenrod', 'golds', 'goldy', 'gone', 'gonna', 'gonzo', 'goo', 'good', 'goodness', 'gosh', 'got', 'gotcha', 'gotta', 'gotten', 'gpink', 'gra', 'grandma', 'grape', 'grapes', 'graphic', 'grass', 'grasslike', 'grassy', 'grat', 'graty', 'gray', 'grayblu', 'grayblue', 'grayed', 'grayes', 'grayets', 'graygreen', 'grayihs', 'graying', 'grayis', 'grayl', 'grayn', 'grayness', 'grays', 'gre', 'grean', 'great', 'greay', 'gree', 'greeb', 'greeeeeeeeeeeen', 'greeeeenst', 'greeeen', 'greeen', 'greeinsh', 'greem', 'green', 'greenand', 'greenblue', 'greengreen', 'greenishgray', 'greenist', 'greenlomel', 'greenn', 'greens', 'greensh', 'greensih', 'greeny', 'greenyellow', 'greep', 'greepink', 'greist', 'gren', 'grene', 'grenn', 'greren', 'greta', 'grety', 'greu', 'greue', 'greuy', 'grey', 'greyblue', 'greybrown', 'greyed', 'greying', 'greyis', 'greyisg', 'greyishblue', 'greyishone', 'greyissh', 'greyist', 'greys', 'greysih', 'greyu', 'grief', 'griege', 'gright', 'grimace', 'grn', 'grocery', 'gross', 'ground', 'group', 'grout', 'grow', 'grows', 'grr', 'grreen', 'grren', 'grrey', 'grrn', 'grrr', 'grrrr', 'grrrrr', 'grrrrrrrrreeeen', 'grrya', 'grteen', 'gry', 'grye', 'gteen', 'guac', 'guess', 'guesses', 'guessing', 'gull', 'gum', 'gunmetal', 'guy', 'guys', 'h', 'ha', 'had', 'hah', 'haha', 'hahaah', 'hahah', 'hahaha', 'hahahaha', 'hahahahahha', 'hahahha', 'hair', 'half', 'halfway', 'halloween', 'halowwen', 'handful', 'hang', 'happen', 'happened', 'happens', 'happy', 'hard', 'has', 'hash', 'hasn', 'hate', 'have', 'haven', 'having', 'hazy', 'hbu', 'hdtv', 'he', 'head', 'heading', 'heads', 'healthy', 'heard', 'heart', 'heat', 'heathered', 'heck', 'heh', 'hehe', 'hell', 'hello', 'help', 'helpful', 'helps', 'hendrix', 'herb', 'here', 'hey', 'heyya', 'hi', 'high', 'highlight', 'highlighted', 'highlights', 'hink', 'hint', 'hinted', 'hints', 'his', 'hit', 'hiya', 'hlad', 'hm', 'hmhm', 'hmm', 'hmmm', 'hmmmm', 'hold', 'holy', 'home', 'homie', 'honestly', 'honey', 'hoo', 'hooo', 'hooray', 'hope', 'hopefully', 'hopeless', 'horrible', 'hot', 'hotdog', 'hotpink', 'hott', 'house', 'housee', 'how', 'howdy', 'howev', 'hrm', 'hte', 'hubabuba', 'hubby', 'hue', 'hues', 'huge', 'huh', 'human', 'hummm', 'humvee', 'hunt', 'hunters', 'hunting', 'hurry', 'hurt', 'hurts', 'hyp', 'i', 'ice', 'icey', 'icing', 'icky', 'icon', 'icy', 'id', 'iddle', 'idea', 'identical', 'idiot', 'idk', 'ieange', 'if', 'ight', 'ignore', 'iis', 'ilght', 'ill', 'im', 'image', 'imagine', 'impossible', 'improving', 'in', 'inbetween', 'indeed', 'indigo', 'industrial', 'ine', 'infront', 'ing', 'ink', 'inot', 'instead', 'instructions', 'int', 'intense', 'intensity', 'interesting', 'intermediate', 'internet', 'intesne', 'inthe', 'into', 'ios', 'ir', 'irabge', 'irange', 'iridescent', 'irritating', 'is', 'isa', 'ishard', 'ismost', 'isn', 'isnt', 'iss', 'issue', 'ist', 'it', 'its', 'ive', 'j', 'jacks', 'jade', 'jealoushy', 'jean', 'jeans', 'jeez', 'jeeze', 'jersey', 'jerseys', 'jesus', 'jet', 'jewel', 'jewelry', 'jimmy', 'jinxed', 'jiob', 'jk', 'jo', 'job', 'john', 'joining', 'joke', 'jr', 'juice', 'jummy', 'jungle', 'just', 'k', 'kacky', 'kakey', 'kakhi', 'kaki', 'kay', 'keep', 'keeps', 'kelly', 'kept', 'kermit', 'kess', 'ketchup', 'khaki', 'kid', 'kidding', 'kight', 'killin', 'killing', 'kind', 'kinda', 'kings', 'kiwi', 'knew', 'kniucle', 'know', 'known', 'knuckle', 'kool', 'kow', 'l', 'la', 'labels', 'lacking', 'lacklust', 'lake', 'lakers', 'lame', 'lant', 'lapis', 'laptop', 'large', 'last', 'lat', 'latte', 'laundry', 'lavand', 'lavend', 'lavendar', 'lavendd', 'lavender', 'lazuli', 'lazy', 'le', 'leaf', 'leafy', 'lean', 'leaning', 'leans', 'learn', 'learning', 'lease', 'least', 'leath', 'leave', 'leaves', 'left', 'leggings', 'legit', 'lel', 'lemon', 'lemonade', 'lemony', 'less', 'let', 'lets', 'lett', 'letting', 'level', 'lght', 'lgiht', 'life', 'ligh', 'lighet', 'lighhhtttt', 'light', 'lightbrown', 'lightes', 'lightests', 'lighth', 'lightt', 'ligt', 'ligth', 'ligyht', 'liike', 'like', 'likea', 'likely', 'lil', 'lilac', 'lilacs', 'lilc', 'liliac', 'lim', 'lime', 'limegreen', 'limes', 'limey', 'limit', 'limoe', 'limr', 'line', 'lining', 'link', 'lipstick', 'listen', 'lit', 'lite', 'literally', 'litle', 'little', 'lively', 'living', 'lizzard', 'lke', 'll', 'lloking', 'lmao', 'location', 'locations', 'logo', 'loks', 'lol', 'lolol', 'lols', 'long', 'look', 'looked', 'lookin', 'looking', 'lookinh', 'looks', 'lool', 'loook', 'loops', 'lord', 'lost', 'lot', 'loud', 'louis', 'love', 'loved', 'lovely', 'low', 'lst', 'lthis', 'lttle', 'luck', 'lucky', 'lue', 'lunch', 'm', 'mac', 'mad', 'madd', 'made', 'magenta', 'magentas', 'magentta', 'magneta', 'mahogany', 'make', 'makes', 'makeup', 'making', 'male', 'man', 'mango', 'mangos', 'many', 'marigold', 'marine', 'mario', 'mark', 'maroon', 'marron', 'marroon', 'mary', 'masculine', 'mash', 'match', 'matches', 'matching', 'matt', 'matte', 'matted', 'maube', 'mauv', 'mauve', 'mauvey', 'mauvy', 'mave', 'may', 'maybe', 'mb', 'me', 'meadow', 'mean', 'meaning', 'means', 'meant', 'med', 'medium', 'meduim', 'meet', 'meets', 'megenta', 'meiduim', 'mellow', 'melon', 'menace', 'mentioned', 'mess', 'messed', 'metal', 'metallic', 'mets', 'mi', 'mic', 'miced', 'mid', 'middel', 'middl', 'middle', 'middleground', 'middling', 'midrange', 'midtone', 'midway', 'might', 'military', 'milk', 'mind', 'minecraft', 'minimum', 'minnesot', 'mint', 'minty', 'miost', 'mis', 'miss', 'missed', 'missing', 'mistake', 'mittens', 'mix', 'mixed', 'mixing', 'mixture', 'mized', 'mm', 'mmm', 'mo', 'moauve', 'mocha', 'moldy', 'mom', 'money', 'monitor', 'monitors', 'monst', 'moon', 'mor', 'more', 'morning', 'mortar', 'mos', 'moss', 'mossi', 'mossy', 'most', 'mostly', 'mot', 'mouse', 'move', 'movie', 'mow', 'mown', 'mtg', 'mturk', 'muave', 'much', 'mucus', 'mud', 'muddi', 'muddy', 'muppet', 'murky', 'musardy', 'mushy', 'muski', 'must', 'mustard', 'mustards', 'mustardy', 'mustardyell', 'mustart', 'mustrad', 'mut', 'mute', 'muted', 'muve', 'my', 'mybad', 'mylanta', 'myself', 'n', 'nah', 'nail', 'name', 'names', 'narwhal', 'nasty', 'nat', 'natural', 'navy', 'naw', 'nawh', 'nbd', 'nd', 'neaon', 'neaqua', 'near', 'nearly', 'need', 'needed', 'negative', 'neith', 'neno', 'neom', 'neon', 'neone', 'neons', 'neony', 'neoon', 'nerves', 'ness', 'netih', 'neutral', 'nev', 'new', 'next', 'nic', 'nice', 'niceeee', 'nick', 'night', 'nighttime', 'niiiiiiice', 'ninentendo', 'ninja', 'nmeded', 'nnnnoooo', 'no', 'nogreen', 'non', 'nonblue', 'none', 'nono', 'nooooo', 'noooooo', 'nope', 'nor', 'normal', 'not', 'notably', 'notbright', 'notbrown', 'notdark', 'noth', 'nothing', 'notpurple', 'now', 'noy', 'np', 'npt', 'npurple', 'nreon', 'nright', 'nthe', 'nude', 'nut', 'nweird', 'o', 'oastel', 'object', 'oblong', 'obnoxious', 'obvious', 'obviously', 'ocean', 'oceanlike', 'ochre', 'odd', 'oddball', 'oe', 'oen', 'of', 'ofe', 'off', 'offshade', 'often', 'og', 'oh', 'ohh', 'ohhh', 'ohio', 'oi', 'oilve', 'oink', 'oj', 'ok', 'okat', 'okay', 'okie', 'okkkk', 'okkkkkk', 'old', 'oliv', 'olive', 'olives', 'olivey', 'olivre', 'olve', 'omg', 'omre', 'on', 'once', 'one', 'onebut', 'ones', 'only', 'onr', 'oo', 'ooh', 'ooo', 'oooh', 'ooops', 'oopps', 'oops', 'oopsies', 'oorange', 'opaque', 'opinion', 'opposite', 'opps', 'ops', 'optic', 'option', 'options', 'or', 'oraange', 'oragange', 'orage', 'oragn', 'oragne', 'oragnge', 'oragreen', 'oranage', 'orane', 'oranfe', 'oranfge', 'orang', 'orange', 'oranged', 'orangeist', 'oranges', 'orangey', 'orangidh', 'orangie', 'orangy', 'orchid', 'ord', 'orders', 'org', 'organ', 'organge', 'orlive', 'ornag', 'ornage', 'ose', 'ot', 'otange', 'otehrs', 'oth', 'others', 'otherwise', 'ouch', 'oueple', 'ouj', 'our', 'ouroke', 'ourple', 'ours', 'out', 'ov', 'overcast', 'overly', 'overtones', 'owe', 'oye', 'oyellow', 'p', 'p8nk', 'pack', 'pain', 'paint', 'painted', 'pal', 'pale', 'palm', 'pap', 'park', 'parrot', 'part', 'participating', 'partn', 'passsed', 'pastel', 'pastels', 'pasty', 'patel', 'patrick', 'pattern', 'paul', 'pay', 'payed', 'paying', 'pdark', 'pea', 'peach', 'peaches', 'peachy', 'peack', 'pear', 'peas', 'pee', 'peel', 'pencil', 'pennies', 'penny', 'people', 'pepto', 'perception', 'perfect', 'perhaps', 'periwickle', 'periwinkle', 'periwinle', 'perriwinkle', 'person', 'personally', 'perwinkle', 'peuple', 'pf', 'phew', 'phot', 'pick', 'picked', 'picking', 'picture', 'pie', 'piggy', 'pigment', 'piink', 'piles', 'pimk', 'pin', 'pine', 'pinik', 'pink', 'pinked', 'pinkgray', 'pinki', 'pinking', 'pinkinsh', 'pinkist', 'pinkl', 'pinks', 'pinksih', 'pinky', 'pinl', 'pinnk', 'pirple', 'piss', 'pistacchio', 'pistachio', 'pit', 'piurple', 'pixels', 'plae', 'plain', 'plant', 'plants', 'plat', 'play', 'played', 'playing', 'ple', 'please', 'pleasure', 'plue', 'plum', 'plumbgrante', 'plums', 'plus', 'pnik', 'pnk', 'poil', 'point', 'policemans', 'ponk', 'pony', 'poo', 'pool', 'poop', 'poopy', 'pop', 'poppi', 'popping', 'poppy', 'pops', 'popular', 'porn', 'posh', 'position', 'possibly', 'pot', 'pow', 'powd', 'ppink', 'ppurple', 'ppurpleist', 'practically', 'precious', 'precise', 'present', 'pretti', 'pretty', 'previous', 'primary', 'primraryblue', 'prince', 'princess', 'priple', 'prob', 'probably', 'problem', 'probly', 'process', 'proclaimed', 'product', 'pronounced', 'prop', 'prp', 'prpl', 'prple', 'prupl', 'pruple', 'prurple', 'prussian', 'ps', 'pu', 'public', 'puce', 'pueple', 'puirple', 'puk', 'puke', 'pukey', 'pumkin', 'pumkins', 'pumpkin', 'pumpkins', 'pumpkn', 'punk', 'pup', 'pupel', 'pupl', 'puple', 'pupr', 'puprle', 'puprple', 'pur', 'purble', 'pure', 'purl', 'purle', 'purlpe', 'purlpl', 'purlple', 'purp', 'purpble', 'purpe', 'purpel', 'purpil', 'purpile', 'purpke', 'purpkle', 'purpl', 'purplblue', 'purple', 'purpleblue', 'purplees', 'purplegrey', 'purpleist', 'purplel', 'purplely', 'purpleo', 'purplepink', 'purplepurple', 'purples', 'purplethe', 'purpletr', 'purpley', 'purpleyellow', 'purpli', 'purplisj', 'purplle', 'purplr', 'purplse', 'purplw', 'purply', 'purpoke', 'purpole', 'purpose', 'purpp', 'purpple', 'purpul', 'puse', 'put', 'putty', 'pyramid', 'q', 'qq', 'qualify', 'quality', 'queed', 'question', 'questions', 'queue', 'quick', 'quit', 'quite', 'r', 'radd', 'radiant', 'radioactive', 'rain', 'rainbow', 'rained', 'raining', 'rainy', 'ral', 'rally', 'random', 'randomly', 'rang', 'range', 'raspberry', 'rath', 'rats', 'ray', 'rd', 're', 'read', 'ready', 'real', 'realistic', 'realized', 'really', 'realy', 'reason', 'recently', 'recov', 'red', 'redd', 'redder', 'reddishbrown', 'reddishe', 'reddishpink', 'reddist', 'reddsih', 'reddy', 'redist', 'redness', 'rednot', 'redpink', 'reds', 'redwood', 'reed', 'reen', 'ref', 'reference', 'reg', 'regular', 'rel', 'related', 'relaxing', 'remaining', 'rememb', 'remianing', 'reminds', 'remotely', 'repeat', 'repeats', 'request', 'res', 'resembles', 'result', 'review', 'rey', 'rgeen', 'rhymes', 'rich', 'richc', 'rid', 'ridiculous', 'right', 'rip', 'ripe', 'rly', 'road', 'roayl', 'robbin', 'robe', 'robin', 'robins', 'rock', 'rockin', 'rocking', 'rofl', 'room', 'rose', 'roses', 'rosey', 'rosi', 'rosy', 'rotten', 'rotting', 'roudn', 'roug', 'rouge', 'rough', 'round', 'rounds', 'roung', 'row', 'roy', 'royah', 'royal', 'royalty', 'royla', 'rple', 'rpurple', 'rred', 'rsky', 'rsut', 'rubb', 'ruby', 'rude', 'rule', 'rulers', 'rules', 'run', 'running', 'rust', 'rusty', 'ryal', 'ryan', 'ryellow', 's', 'sad', 'sadness', 'safety', 'sag', 'sage', 'sagey', 'said', 'salmon', 'salmone', 'salmony', 'same', 'sand', 'sandstone', 'sandy', 'sang', 'saturated', 'saturation', 'saw', 'say', 'saying', 'says', 'school', 'schoolbus', 'scree', 'screen', 'screens', 'sea', 'seafoam', 'seafoamy', 'seagreen', 'seahawk', 'seahawks', 'seal', 'seattkle', 'seattle', 'seawat', 'seaweed', 'sec', 'second', 'see', 'seeemed', 'seeing', 'seem', 'seemingly', 'seems', 'seen', 'select', 'self', 'send', 'sense', 'seriously', 'set', 'setting', 'settings', 'sevee', 'sexist', 'sfavorite', 'sgood', 'shad', 'shade', 'shaded', 'shadeof', 'shades', 'shading', 'shadow', 'shae', 'shafe', 'shake', 'shamrock', 'shape', 'shark', 'sharp', 'she', 'sherbert', 'sherrie', 'shickingly', 'shinny', 'shiny', 'ship', 'shirt', 'shit', 'shock', 'shocking', 'shoes', 'shoot', 'should', 'shouldve', 'show', 'shrek', 'shrugs', 'shy', 'sick', 'side', 'sidewalk', 'sidnna', 'sigh', 'sign', 'silly', 'silv', 'silver', 'silvery', 'simalar', 'similar', 'siml', 'simlar', 'since', 'sing', 'single', 'sipping', 'sir', 'sk', 'skies', 'skin', 'skt', 'sky', 'skylike', 'skys', 'slacks', 'slamon', 'slat', 'slate', 'slighltly', 'slighlty', 'slighly', 'slight', 'slightlu', 'slightly', 'slighty', 'slime', 'slimy', 'slippers', 'slivre', 'slo', 'slow', 'slughtly', 'small', 'smart', 'smell', 'smells', 'smog', 'smoke', 'smokey', 'snot', 'so', 'soda', 'soe', 'soft', 'solid', 'solor', 'solors', 'some', 'someone', 'something', 'sometimes', 'somewhat', 'somewhere', 'song', 'soo', 'soooo', 'soothing', 'sorrrryyy', 'sorrry', 'sorry', 'sort', 'sorta', 'sory', 'soudns', 'sound', 'sounds', 'soup', 'southw', 'sp', 'sparrow', 'speak', 'speaking', 'spearmint', 'spectrum', 'speed', 'spell', 'spelled', 'spelling', 'spicy', 'spilled', 'spit', 'split', 'spray', 'spring', 'sprry', 'square', 'squares', 'squars', 'squash', 'squatty', 'squint', 'squinting', 'squirt', 'srry', 'sry', 'st', 'stalks', 'stand', 'standard', 'stands', 'start', 'starting', 'starts', 'stated', 'states', 'stay', 'steel', 'steely', 'stems', 'step', 'sticks', 'stiks', 'still', 'stink', 'stinking', 'stomach', 'stone', 'stones', 'stop', 'store', 'storm', 'stormy', 'straight', 'strawberry', 'street', 'stress', 'strong', 'strp', 'stuff', 'stupid', 'subdued', 'subtle', 'subtly', 'such', 'suck', 'sucked', 'suede', 'sugg', 'summ', 'sun', 'sunflow', 'sunny', 'sunset', 'sunshine', 'sup', 'superman', 'suppose', 'supposed', 'sure', 'swear', 'sweet', 'sweetness', 'swim', 'swimming', 't', 't5he', 'tab', 'tacki', 'tad', 'take', 'talk', 'talking', 'tame', 'tan', 'tanb', 'tangerine', 'tanist', 'tank', 'tann', 'tanned', 'tanning', 'tanny', 'tans', 'target', 'targets', 'tart', 'task', 'taste', 'taupe', 'tblue', 'tcu', 'tea', 'teaal', 'teal', 'tealgreen', 'teals', 'tealy', 'team', 'teammwork', 'teamwork', 'tee', 'teeal', 'teenagers', 'teh', 'tela', 'tell', 'tellow', 'tellows', 'tempalte', 'template', 'tend', 'tennessee', 'tennis', 'tent', 'terms', 'terra', 'terracotta', 'terrible', 'text', 'tge', 'than', 'thank', 'thanks', 'thanks1', 'thanksgiving', 'that', 'thats', 'the', 'thedark', 'thee', 'them', 'then', 'there', 'theres', 'these', 'they', 'theyre', 'thhe', 'thin', 'thing', 'things', 'think', 'thinkg', 'thinking', 'third', 'this', 'thop', 'thoroughly', 'those', 'though', 'thought', 'thoughts', 'thougth', 'thr', 'thre', 'three', 'through', 'throw', 'throwing', 'throws', 'thse', 'tht', 'thumb', 'thw', 'thx', 'ticket', 'tied', 'tiffany', 'tig', 'tile', 'tim', 'time', 'times', 'tine', 'tinge', 'tinged', 'tinges', 'tinit', 'tink', 'tinnt', 'tint', 'tinted', 'tinting', 'tiny', 'tired', 'tires', 'tks', 'tne', 'to', 'today', 'toddl', 'toe', 'togeth', 'toilet', 'told', 'tomato', 'tone', 'toned', 'tones', 'too', 'topical', 'torquois', 'torquoise', 'torquoisw', 'torture', 'total', 'totally', 'touch', 'tough', 'toughie', 'tought', 'toupe', 'touriques', 'tourqoise', 'tourqouise', 'tourquoise', 'toward', 'towards', 'toxic', 'tractor', 'tradional', 'traditional', 'traditionally', 'traffic', 'tranquil', 'tranquility', 'trash', 'tree', 'trees', 'trending', 'trf', 'trick', 'tricky', 'tropical', 'trouble', 'trtn', 'tru', 'true', 'trueist', 'trump', 'trunk', 'trust', 'try', 'trying', 'tt', 'tthe', 'tuff', 'turkernation', 'turkmast', 'turkopitcon', 'turkquoise', 'turn', 'turned', 'turning', 'turns', 'turqoie', 'turqoise', 'turqoiuse', 'turqooise', 'turqouise', 'turqouse', 'turquiose', 'turquiouse', 'turquise', 'turquisy', 'turquois', 'turquoise', 'turquoisey', 'turquose', 'turtle', 'tutus', 'tweetie', 'twice', 'twilight', 'two', 'ty', 'typ', 'type', 'typed', 'typical', 'typically', 'typing', 'typo', 'u', 'u2', 'ue', 'ugh', 'ughh', 'ughhh', 'ugli', 'ugly', 'uh', 'uhh', 'uhhh', 'uhhhhh', 'uhhm', 'uhm', 'uhmm', 'uhoh', 'um', 'umm', 'ummm', 'ummmm', 'ummmnot', 'understand', 'understanding', 'undertone', 'undertones', 'underwat', 'uniform', 'uniforms', 'union', 'unique', 'united', 'unless', 'unlike', 'unnatural', 'unsaturated', 'unsweeten', 'up', 'urine', 'urple', 'us', 'used', 'using', 'usixels', 'usual', 'usually', 'uv', 'valentine', 'value', 'values', 'variation', 'variations', 'varients', 'vary', 've', 'vegetation', 'veggie', 'vegie', 'verge', 'version', 'versus', 'very', 'vibrant', 'vibrantly', 'vibratnt', 'viiolet', 'viking', 'vikings', 'viloet', 'violet', 'violets', 'vivd', 'vivid', 'vivied', 'vlose', 'vlue', 'vocabulary', 'voilet', 'volunte', 'volunteers', 'vomit', 'vomited', 'vote', 'w', 'wack', 'waht', 'wait', 'waiting', 'walpap', 'wanna', 'want', 'wanted', 'war', 'warm', 'warning', 'was', 'wasabi', 'washed', 'washout', 'wasn', 'wat', 'watching', 'watered', 'watermelon', 'watermelong', 'watermelons', 'watery', 'way', 'ways', 'we', 'weak', 'wear', 'weathered', 'weeds', 'weird', 'welcome', 'well', 'went', 'were', 'wet', 'weve', 'whales', 'what', 'whatev', 'whats', 'wheat', 'when', 'where', 'whereas', 'whew', 'which', 'while', 'whit', 'white', 'whitre', 'who', 'whoops', 'why', 'wiat', 'wiith', 'will', 'williamsburg', 'wilma', 'wind', 'wine', 'winkle', 'wins', 'wintergreen', 'wisley', 'with', 'witha', 'withering', 'without', 'witrh', 'wityh', 'wohoo', 'wohooo', 'wohoooo', 'woman', 'women', 'won', 'wond', 'wonderful', 'wondering', 'wonky', 'wont', 'woo', 'wood', 'woohoo', 'wooo', 'woot', 'word', 'worded', 'worj', 'work', 'workign', 'working', 'works', 'worm', 'worn', 'worrie', 'worried', 'worries', 'worroes', 'worrries', 'worry', 'worst', 'worth', 'woth', 'would', 'wouldn', 'wouldnt', 'wow', 'wright', 'write', 'wrong', 'wrote', 'wtf', 'wtg', 'wuite', 'xd', 'xp', 'y', 'ya', 'yaaay', 'yaeeaaa', 'yah', 'yahoo', 'yallow', 'yard', 'yay', 'yaya', 'yayyy', 'ye', 'yea', 'yeah', 'yeallow', 'years', 'yeellow', 'yeh', 'yel', 'yell', 'yelliow', 'yelllllllow', 'yelllow', 'yelllowy', 'yello', 'yelloe', 'yelloow', 'yellow', 'yellowgreen', 'yellowis', 'yellowist', 'yellowly', 'yellows', 'yellowwww', 'yellowy', 'yelloy', 'yellw', 'yellwo', 'yeloow', 'yelow', 'yep', 'yes', 'yess', 'yessir', 'yet', 'yew', 'yikes', 'yippee', 'yllow', 'yllw', 'ylow', 'yo', 'york', 'you', 'youd', 'your', 'youre', 'yours', 'yourself', 'yrp', 'ys', 'yuck', 'yucky', 'yuk', 'yup', 'ywllow', 'zoning', '$UNK']\n"]}]},{"cell_type":"markdown","source":["# Transformer Model & Experiments"],"metadata":{"id":"A1-MSlOeSD-4"}},{"cell_type":"code","source":["import torch\n","\n","class ColorDataset(torch.utils.data.Dataset):\n","    \"\"\"\n","    PyTorch dataset for contextual color describers. The primary\n","    function of this dataset is to organize the raw data into\n","    batches of Tensors of the appropriate shape and type. When\n","    using this dataset with `torch.utils.data.DataLoader`, it is\n","    crucial to supply the `collate_fn` method as the argument for\n","    the `DataLoader.collate_fn` parameter.\n","\n","    Parameters\n","    ----------\n","    color_seqs : list of lists of lists of floats, or np.array\n","        Dimension (m, n, p) where m is the number of examples, n is\n","        the number of colors in each context, and p is the length\n","        of the color representations.\n","\n","    word_seqs : list of list of int\n","        Dimension m, the number of examples. The length of each\n","        sequence can vary.\n","\n","    ex_lengths : list of int\n","        Dimension m. Each value gives the length of the corresponding\n","        word sequence in `word_seqs`.\n","\n","    \"\"\"\n","    def __init__(self, color_seqs, word_seqs, ex_lengths):\n","        assert len(color_seqs) == len(ex_lengths)\n","        assert len(color_seqs) == len(word_seqs)\n","        self.color_seqs = color_seqs\n","        self.word_seqs = word_seqs\n","        self.ex_lengths = ex_lengths\n","\n","    @staticmethod\n","    def collate_fn(batch):\n","        \"\"\"\n","        Function for creating batches.\n","\n","        Parameter\n","        ---------\n","        batch : tuple of length 3\n","            Contains the `color_seqs`, `word_seqs`, and `ex_lengths`,\n","            all as lists or similar Python iterables. The function\n","            turns them into Tensors.\n","\n","        Returns\n","        -------\n","        color_seqs : torch.FloatTensor.\n","             The shape is `(m, n, p)` where `m` is the batch_size,\n","             `n` is the number of colors in each context, and `p` is\n","             the color dimensionality.\n","\n","        word_seqs : torch.LongTensor\n","            This is a padded sequence, dimension (m, k), where `m` is\n","            the batch_size and `k` is the length of the longest sequence\n","            in the batch.\n","\n","        ex_lengths : torch.LongTensor\n","            The true lengths of each sequence in `word_seqs. This will\n","            have shape `(m, )`, where `m` is the batch_size.\n","\n","        targets :  torch.LongTensor\n","            This is a padded sequence, dimension (m, k-1), where `m` is\n","            the batch_size and `k` is the length of the longest sequence\n","            in the batch. The targets match `word_seqs` except we drop the\n","            first symbol, as it is always START_SYMBOL. When the loss is\n","            calculated, we compare this sequence to `word_seqs` excluding\n","            the final character, which is always the END_SYMBOL. The result\n","            is that each timestep t is trained to predict the symbol\n","            at t+1.\n","\n","        \"\"\"\n","        color_seqs, word_seqs, ex_lengths = zip(*batch)\n","        # Conversion to Tensors:\n","        color_seqs = torch.FloatTensor(color_seqs)\n","        word_seqs = [torch.LongTensor(seq) for seq in word_seqs]\n","        ex_lengths = torch.LongTensor(ex_lengths)\n","        # Targets as next-word predictions:\n","        targets = [x[1:, ] for x in word_seqs]\n","        # Word Inputs:\n","        inputs = [x[:-1, ] for x in word_seqs]\n","        # Padding\n","        word_seqs = torch.nn.utils.rnn.pad_sequence(\n","            inputs, batch_first=True)\n","        targets = torch.nn.utils.rnn.pad_sequence(\n","            targets, batch_first=True)\n","        return color_seqs, word_seqs, ex_lengths, targets\n","\n","    def __len__(self):\n","        return len(self.color_seqs)\n","\n","    def __getitem__(self, idx):\n","        return self.color_seqs[idx], self.word_seqs[idx], self.ex_lengths[idx]"],"metadata":{"id":"-fWzgHF1hGKc","executionInfo":{"status":"ok","timestamp":1654408137812,"user_tz":420,"elapsed":13,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","execution_count":22,"metadata":{"id":"ZyCOnCcbCj6X","executionInfo":{"status":"ok","timestamp":1654408138060,"user_tz":420,"elapsed":260,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["from torch_color_describer import EncoderDecoder, ContextualColorDescriber\n","import torch\n","import torch.nn as nn\n","from IPython.core.debugger import set_trace\n","import math\n","\n","def create_pad_mask(matrix: torch.tensor, pad_token: int) -> torch.tensor:\n","      return (matrix == pad_token)\n","\n","class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model, dropout=0.2, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)\n","\n","class TransformerColorizedEncoderDecoder(nn.Module):\n","\n","    def __init__(self, vocab_size, embedding, embed_dim, hidden_dim, \n","                 transformer_args, device, freeze_embedding=False):\n","        super().__init__()\n","\n","        nhead = transformer_args['nhead']\n","        num_encoder_layers = transformer_args['num_encoder_layers']\n","        num_decoder_layers = transformer_args['num_decoder_layers']\n","        dim_feedforward = transformer_args['dim_feedforward']\n","        dropout = transformer_args['dropout']\n","\n","        self.color_dim = 54\n","        self.hidden_dim = hidden_dim\n","        self.rnn = nn.LSTM(\n","            input_size=self.color_dim,\n","            hidden_size=self.hidden_dim,\n","            #num_layers=3,\n","            bidirectional = True,\n","            batch_first=True)\n","\n","        self.transformer_model = nn.Transformer(d_model = embed_dim, \n","                                                batch_first = True, \n","                                                nhead = nhead, \n","                                                num_encoder_layers=num_encoder_layers,\n","                                                num_decoder_layers= num_decoder_layers,\n","                                                dim_feedforward = dim_feedforward,\n","                                                dropout = dropout)\n","        \n","        self.positionalEncoder = PositionalEncoding(d_model = embed_dim)\n","        self.outputter = nn.Linear(embed_dim, vocab_size)\n","        self.freeze_embedding = freeze_embedding\n","        self.embedding = self._define_embedding(\n","            embedding, vocab_size, embed_dim, self.freeze_embedding)\n","        self.embed_dim = self.embedding.embedding_dim\n","\n","        self.device = device\n","    \n","    def forward(self, color_seqs, word_seqs, seq_lengths=None, hidden=None, targets=None):\n","\n","        tgt = self.embedding(word_seqs) * math.sqrt(self.embed_dim)\n","        original_mask = self.transformer_model.generate_square_subsequent_mask(sz = word_seqs.shape[1]).to(self.device)\n","        padding_mask = create_pad_mask(word_seqs, 0)\n","\n","        enc_output, hc = self.rnn(color_seqs)\n","\n","        src, cs = hc\n","\n","        src = src.permute(1, 0, 2)\n","\n","        tgt = self.positionalEncoder(tgt) \n","\n","        trans_output = self.transformer_model(src, tgt, tgt_mask=original_mask, tgt_key_padding_mask=padding_mask)\n","\n","        linear_output = self.outputter(trans_output.permute(1, 0, 2))\n","        dec_output = linear_output.permute(1, 2, 0)\n","\n","        if self.training:\n","            return dec_output\n","        else:\n","            return dec_output, enc_output #We do not use hidden states in making predictions\n","    \n","    @staticmethod\n","    def _define_embedding(embedding, vocab_size, embed_dim, freeze_embedding):\n","        if embedding is None:\n","            emb = nn.Embedding(vocab_size, embed_dim)\n","            emb.weight.requires_grad = not freeze_embedding\n","            return emb\n","        else:\n","            embedding = torch.FloatTensor(embedding)\n","            return nn.Embedding.from_pretrained(\n","                embedding, freeze=freeze_embedding)\n","            \n","class ColorizedInputDescriberTransformer(ContextualColorDescriber):\n","\n","    def __init__(self,\n","            vocab,\n","            embedding=None,\n","            embed_dim=50,\n","            hidden_dim=50,\n","            freeze_embedding=False,\n","            transformer_args = None,\n","            device = None,\n","            **base_kwargs):\n","      super().__init__(vocab, embedding, embed_dim, hidden_dim, freeze_embedding, **base_kwargs)\n","\n","      if transformer_args is not None:\n","        self.transformer_args = transformer_args\n","      else:\n","        self.transformer_args = {'nhead': 10, \n","                    'num_encoder_layers': 3,\n","                    'num_decoder_layers': 3,\n","                    'dim_feedforward': 2048,\n","                    'dropout': 0.2,\n","                    }\n","\n","    def build_dataset(self, color_seqs, word_seqs):\n","        \"\"\"\n","        Create a dataset from a list of color contexts and\n","        associated utterances.\n","\n","        Parameters\n","        ----------\n","        color_seqs : list of lists of color representations\n","            We assume that each context has the same number of colors,\n","            each with the same shape.\n","\n","        word_seqs : list of lists of utterances\n","            A tokenized list of words. This method uses `self.word2index`\n","            to turn this into a list of lists of indices.\n","\n","        Returns\n","        -------\n","                ColorDataset\n","\n","        \"\"\"\n","        self.color_dim = len(color_seqs[0][0])\n","        word_seqs = [[self.word2index.get(w, self.unk_index) for w in seq]\n","                     for seq in word_seqs]\n","        ex_lengths = [len(seq) for seq in word_seqs]\n","        return ColorDataset(color_seqs, word_seqs, ex_lengths)\n","\n","    def build_graph(self):\n","\n","        return TransformerColorizedEncoderDecoder(vocab_size = self.vocab_size,\n","                                                  embedding=self.embedding,\n","                                                  embed_dim=self.embed_dim,\n","                                                  hidden_dim=self.hidden_dim,\n","                                                  transformer_args = self.transformer_args,\n","                                                  device = self.device,\n","                                                  freeze_embedding=self.freeze_embedding)\n","                \n","    def predict_proba(self, color_seqs, word_seqs, device=None):\n","        \"\"\"\n","        Calculate the predicted probabilities of the sequences in\n","        `word_seqs` given the color contexts in `color_seqs`.\n","\n","        Parameters\n","        ----------\n","        color_seqs : list of lists of lists of floats, or np.array\n","            Dimension (m, n, p) where m is the number of examples, n is\n","            the number of colors in each context, and p is the length\n","            of the color representations.\n","\n","        word_seqs : list of list of int\n","            Dimension m, the number of examples. The length of each\n","            sequence can vary.\n","\n","        device: str or None\n","            Allows the user to temporarily change the device used\n","            during prediction. This is useful if predictions require a\n","            lot of memory and so are better done on the CPU. After\n","            prediction is done, the model is returned to `self.device`.\n","\n","        Returns\n","        -------\n","        list of lists of predicted probabilities. In other words,\n","        for each example, at each timestep, there is a probability\n","        distribution over the entire vocabulary.\n","\n","        \"\"\"\n","        device = self.device if device is None else torch.device(device)\n","\n","        dataset = self.build_dataset(color_seqs, word_seqs)\n","\n","        dataloader = self._build_dataloader(dataset, shuffle=False)\n","\n","        self.model.to(device)\n","\n","        self.model.eval()\n","\n","        softmax = nn.Softmax(dim=2)\n","\n","        start_probs = np.zeros(self.vocab_size)\n","        start_probs[self.start_index] = 1.0\n","\n","        all_probs = []\n","\n","        with torch.no_grad():\n","\n","            for batch_colors, batch_words, batch_lens, targets in dataloader:\n","\n","                batch_colors = batch_colors.to(device)\n","                batch_words = batch_words.to(device)\n","                batch_lens = batch_lens.to(device)\n","\n","                output, _ = self.model(\n","                    color_seqs=batch_colors,\n","                    word_seqs=batch_words,\n","                    seq_lengths=batch_lens)\n","\n","                output = output.permute(0, 2, 1)\n","                probs = softmax(output)\n","                probs = probs.cpu().numpy()\n","                probs = np.insert(probs, 0, start_probs, axis=1)\n","                all_probs += [p[: n] for p, n in zip(probs, batch_lens)]\n","\n","        self.model.to(self.device)\n","\n","        return all_probs\n","\n","    def predict(self, color_seqs, max_length=20, device=None):\n","\n","        device = self.device if device is None else torch.device(device)\n","\n","        self.model.to(device)\n","\n","        self.model.eval()\n","\n","        preds = []\n","\n","        for color_seq in color_seqs:\n","\n","            pred = []\n","            color_seq = torch.FloatTensor([color_seq])\n","            color_seq = color_seq.to(device)\n","\n","            with torch.no_grad():\n","                # Start with START_SYMBOL for all examples:\n","                decoder_input = [[self.start_index]]\n","                decoder_input = torch.LongTensor(decoder_input)\n","                decoder_input = decoder_input.to(device)\n","\n","                # Now move through the remaiming timesteps using the\n","                # previous timestep to predict the next one:\n","\n","                for i in range(1, max_length):\n","\n","                    output, _ = self.model(\n","                        color_seqs=color_seq,\n","                        word_seqs=decoder_input,\n","                        seq_lengths=None)\n","\n","                    # Always take the highest probability token to\n","                    # be the prediction:  \n","                    p = output[:,:, -1].argmax(1).view(1,1)\n","\n","                    decoder_input = torch.cat((decoder_input, p), axis = 1)\n","\n","            # Convert all the predictions from indices to elements of\n","            # `self.vocab`:\n","            #preds = torch.cat(preds, axis=1)\n","            preds.append(self._convert_predictions(decoder_input))\n","\n","        self.model.to(self.device)\n","\n","        return preds\n","\n","    def _convert_predictions(self, pred):\n","        rep = []\n","        for i in pred[0]:\n","            i = i.item()\n","            rep.append(self.index2word[i])\n","            if i == self.end_index:\n","                return rep\n","        return rep"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"3qC8S01cuSS0","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"4e61117e-d050-41e2-abbb-82f611ce114b","executionInfo":{"status":"error","timestamp":1654408612037,"user_tz":420,"elapsed":473979,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:76: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","/content/gdrive/MyDrive/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 1 of 1000; error is 324.95542937517166"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.41617021276595745\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/MyDrive/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 2 of 1000; error is 127.65529555082321"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.5708510638297872\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/MyDrive/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 3 of 1000; error is 108.10042688250542"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.7427659574468085\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/MyDrive/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 4 of 1000; error is 99.13105320930481"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.7982978723404255\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/MyDrive/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 5 of 1000; error is 95.02046360075474"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.816595744680851\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/MyDrive/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 6 of 1000; error is 93.30912244319916"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8219148936170213\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/MyDrive/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 7 of 1000; error is 89.30602982640266"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8357446808510638\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/MyDrive/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 8 of 1000; error is 88.03554648160934"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8406382978723405\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/MyDrive/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 9 of 1000; error is 84.80668909847736"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8440425531914894\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/MyDrive/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 10 of 1000; error is 83.12979145348072"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.855531914893617\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/MyDrive/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-97f9565f4d66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m save_csv = 'transformer_test.csv')\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time _ = dev_trans.fit(dev_cols_train[:], dev_seqs_train[:])'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#evaluation = dev_trans.evaluate(dev_cols_test[:], dev_seqs_test[:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/cs224u/torch_model_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_no_improvement_count_early_stopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_improvement_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_no_change\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                     utils.progress_bar(\n","\u001b[0;32m/content/gdrive/MyDrive/cs224u/torch_model_base.py\u001b[0m in \u001b[0;36m_update_no_improvement_count_early_stopping\u001b[0;34m(self, *dev)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \"\"\"\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;31m# If the score isn't at least `self.tol` better, increment:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/cs224u/torch_color_describer.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, color_seqs, word_seqs, device)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \"\"\"\n\u001b[0;32m--> 785\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcorpus_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/cs224u/torch_color_describer.py\u001b[0m in \u001b[0;36mlistener_accuracy\u001b[0;34m(self, color_seqs, word_seqs, device)\u001b[0m\n\u001b[1;32m    773\u001b[0m         \"\"\"\n\u001b[1;32m    774\u001b[0m         gold, predicted = self.listener_predictions(\n\u001b[0;32m--> 775\u001b[0;31m             color_seqs, word_seqs, device=device)\n\u001b[0m\u001b[1;32m    776\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/cs224u/torch_color_describer.py\u001b[0m in \u001b[0;36mlistener_predictions\u001b[0;34m(self, color_seqs, word_seqs, device)\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0mtarget_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_seq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             min_perp, pred, pred_index = self.listener_predict_one(\n\u001b[0;32m--> 763\u001b[0;31m                 color_seq, word_seq, device=device)\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0mgold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/cs224u/torch_color_describer.py\u001b[0m in \u001b[0;36mlistener_predict_one\u001b[0;34m(self, context, seq, device)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;31m# All perplexities:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m         \u001b[0mperps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperplexities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;31m# Ranking, using `order_indices` rather than colors and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/cs224u/torch_color_describer.py\u001b[0m in \u001b[0;36mperplexities\u001b[0;34m(self, color_seqs, word_seqs, device)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \"\"\"\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-94dadbedbdf6>\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, color_seqs, word_seqs, device)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mall_probs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mall_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     def register_backward_hook(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m                     \u001b[0mgrad_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#BEST MODEL\n","\n","transformer_args = {'nhead': 10, \n","                    'num_encoder_layers': 3,\n","                    'num_decoder_layers': 6,\n","                    'dim_feedforward': 128,\n","                    'dropout': 0.2,\n","                    }\n","\n","dev_trans = ColorizedInputDescriberTransformer(\n","dev_glove_vocab,\n","embedding = dev_glove_embedding, \n","embed_dim = 50,\n","hidden_dim = 50,\n","transformer_args = transformer_args,\n","early_stopping=True,\n","batch_size = 256,\n","save_csv = 'transformer_test.csv')\n","\n","%time _ = dev_trans.fit(dev_cols_train[:], dev_seqs_train[:])\n","\n","#evaluation = dev_trans.evaluate(dev_cols_test[:], dev_seqs_test[:])\n","#print('Listener Accuracy: ', evaluation['listener_accuracy'])\n","#print('Corp BLEU', evaluation['corpus_bleu'])\n","#print('----------------------------------------------------------------------------------')"]},{"cell_type":"code","source":["corpus = dev_corpus.read()\n","\n","for i in range(20):\n","  ex = next(corpus)\n","  ex.display()"],"metadata":{"id":"E2c9Fe6944-r","executionInfo":{"status":"aborted","timestamp":1654408612036,"user_tz":420,"elapsed":7,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LF8nf4bUCj6X"},"source":["## Bakeoff [1 point]"]},{"cell_type":"markdown","metadata":{"id":"z6ukT4wXCj6X"},"source":["For the bake-off, we will use our original test set. The function you need to run for the submission is the following, which uses your `evaluate_original_system` from above:"]},{"cell_type":"code","source":["def evaluate_original_system(trained_model, color_seqs_test, texts_test):\n","    \"\"\"\n","    Feel free to modify this code to accommodate the needs of\n","    your system. Just keep in mind that it will get raw corpus\n","    examples as inputs for the bake-off.\n","\n","    \"\"\"\n","    # `word_seqs_test` is a list of strings, so tokenize each of\n","    # its elements:\n","    tok_seqs = [tokenize_example(s) for s in texts_test]\n","\n","    col_seqs = [represent_color_context(colors)\n","                for colors in color_seqs_test]\n","\n","\n","    # Optionally include other preprocessing steps here. Note:\n","    # DO NOT RETRAIN YOUR MODEL AS PART OF THIS EVALUATION!\n","    # It's a tempting step, but it's a mistake and will get\n","    # you disqualified!\n","\n","    # The following core score calculations are required:\n","    evaluation = trained_model.evaluate(col_seqs, tok_seqs)\n","\n","    return evaluation"],"metadata":{"id":"VnZojPqFZcDv","executionInfo":{"status":"aborted","timestamp":1654408612036,"user_tz":420,"elapsed":7,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YSzc0yAZCj6X","executionInfo":{"status":"aborted","timestamp":1654408612037,"user_tz":420,"elapsed":8,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["def create_bakeoff_submission(\n","        trained_model,\n","        output_filename='cs224u-colors-bakeoff-entry-transformer.csv'):\n","    bakeoff_src_filename = os.path.join(\n","        \"data\", \"colors\", \"cs224u-colors-test.csv\")\n","\n","    bakeoff_corpus = ColorsCorpusReader(bakeoff_src_filename)\n","\n","    # This code just extracts the colors and texts from the new corpus:\n","    bakeoff_rawcols, bakeoff_texts = zip(*[\n","        [ex.colors, ex.contents] for ex in bakeoff_corpus.read()])\n","\n","    # Original system function call; `trained_model` is your trained model:\n","    evaluation = evaluate_original_system(\n","        trained_model, bakeoff_rawcols, bakeoff_texts)\n","\n","    evaluation['bakeoff_text'] = bakeoff_texts\n","\n","    df = pd.DataFrame(evaluation)\n","    df.to_csv(output_filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FqkccylGCj6Y","executionInfo":{"status":"aborted","timestamp":1654408612037,"user_tz":420,"elapsed":8,"user":{"displayName":"Bryan Chia","userId":"02605844331798057059"}}},"outputs":[],"source":["# This check ensure that the following code only runs on the local environment only.\n","# The following call will not be run on the autograder environment.\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","    pass\n","    create_bakeoff_submission(dev_trans)"]},{"cell_type":"markdown","source":["# Analysis with Test Output"],"metadata":{"id":"6riypRV2HGLM"}},{"cell_type":"code","source":["bakeoff_src_filename = os.path.join(\"data\", \"colors\", \"cs224u-colors-test.csv\")\n","\n","bakeoff_corpus = ColorsCorpusReader(bakeoff_src_filename)"],"metadata":{"id":"U-dB1pxdHEjA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corpus = bakeoff_corpus.read()\n","\n","for i in range(2024):\n","  ex = next(corpus)\n","  if i in [5, 54, 258, 431, 737, 1116, 1424, 2024]:\n","    ex.display()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":615},"id":"endt-B_pKpVD","outputId":"aa416373-3ceb-4af0-d15e-aaa59b18d442"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gray green\n","grey\n","Dark gray\n","medium slate\n","Gray\n","muted suede brown\n","medium gray\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 216x72 with 3 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABIElEQVR4nO3YMU7DQBBAURvlyHEJBCidO28ugIILS6t83mvtYkb6GllexxgLlLzNHgDOJmpyRE2OqMkRNTmXZw+/P28v/2vk4+u2Hnnvvv28/K7LsizX/f3Pfdd1Tew6xvh1V5eaHFGTI2pynn5T8z/s+3X2CIds2/3Qey41OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanIuswdgvm27zx7hVC41OaImR9TkrGOM2TPAqVxqckRNjqjJETU5oiZH1OQ8AFhRFv0zi2afAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 216x72 with 3 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABJUlEQVR4nO3YQUrDUBRA0XzpNnXsFox0VGy34FgX+t2A1AwCoddzpsngPbg8Qsacc4GSp6MHgL2JmhxRkyNqckRNzunew/fr+eF/jXysl7Hlvdfvl4ffdVmW5fP56899xxiJXeecv+7qUpMjanJETc7db2r+h+vl7egRNlnPt03vudTkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyTkdPQDHW8+3o0fYlUtNjqjJETU5Y8559AywK5eaHFGTI2pyRE2OqMkRNTk/JM4XBZYQjDYAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 216x72 with 3 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABH0lEQVR4nO3YwUrDUBBA0TzpJ1vdGdKd1X9+/oDULAKh13O2yWIGLkPImHMuUPJy9gBwNFGTI2pyRE2OqMm5PHp4vX8//a+Rr7fXse+9z6ffdVmW5Xp//3PfMUZi1znnr7u61OSImhxRk/Pwm5r/Yd0+zh5hl2297XrPpSZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNzuXsATjftt7OHuFQLjU5oiZH1OSMOefZM8ChXGpyRE2OqMkRNTmiJkfU5PwAunoXCa+dhBwAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 216x72 with 3 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABKElEQVR4nO3YsUrEUBBA0TzZb9XGUgW32MLCBbW00Z99/oCsKQJhr+e0STEDlyFkzDkXKLnZewDYmqjJETU5oiZH1OQcLj18fPq4+l8j728PY81793ffV7/rsizL59ftn/uOMRK7zjl/3dWlJkfU5IianIvf1PwPr88ve4+wyvF8WvWeS02OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IianMPeA7C/4/m09wibcqnJETU5oiZnzDn3ngE25VKTI2pyRE2OqMkRNTmiJucHPxQXBmXPVvgAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 216x72 with 3 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABJElEQVR4nO3YwUrDUBBA0UT6wQoubKAroXUh6B8/f0BqFoFHr+dsk8UMXIaQdYyxQMnT7AHgaKImR9TkiJocUZNzuvfw5fX74X+NfH0+r3ve2z7OD7/rsizL9e32577ruiZ2HWP8uqtLTY6oyRE1OXe/qfkfru/n2SPssl1uu95zqckRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTc5o9APNtl9vsEQ7lUpMjanJETc46xpg9AxzKpSZH1OSImhxRkyNqckRNzg8r+hcFd+9fRAAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 216x72 with 3 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABJklEQVR4nO3YsUrEUBBA0TzZv1VsFNzKwioL2oh+7/MHZE0RCHs9p02KGbgMIWPOuUDJ3dEDwN5ETY6oyRE1OaIm53Tt4ffjw83/Grn//Bpb3nt+/bj5XZdlWd7fnv7cd4yR2HXO+euuLjU5oiZH1ORc/abmf1jPL0ePsMl5vWx6z6UmR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETc7p6AE43nm9HD3CrlxqckRNjqjJGXPOo2eAXbnU5IiaHFGTI2pyRE2OqMn5AWPAFxAedBx9AAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 216x72 with 3 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABI0lEQVR4nO3YsU3EQBBAURtdp9AEhsAB3DUBtS4NoMOBpdV93kvtYEb6GllexxgLlDzNHgDOJmpyRE2OqMkRNTmXew9ftu+H/zXydX1ej7z3dn1/+F2XZVk+t48/913XNbHrGOPXXV1qckRNjqjJuftNzf9w3V9nj3DItt8OvedSkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oibnMnsA5tv22+wRTuVSkyNqckRNzjrGmD0DnMqlJkfU5IiaHFGTI2pyRE3OD4eNFwh+yFnhAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["df_transformer = pd.read_csv('cs224u-colors-bakeoff-entry.csv')\n","df_glove = pd.read_csv('cs224u-colors-bakeoff-entry-glove.csv')"],"metadata":{"id":"fGCQq4mQStmd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Glove Baseline Test"],"metadata":{"id":"oDQmRUw4hYqs"}},{"cell_type":"code","source":["dev_mod_glove = ContextualColorDescriber(\n","    dev_glove_vocab,\n","    embedding=dev_glove_embedding,\n","    early_stopping=True,\n","    save_csv = 'logs/glove_test.csv')\n","\n","%time _ = dev_mod_glove.fit(dev_cols_train[:], dev_seqs_train[:])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XSIFLz6TK0Fp","outputId":"ad9ef16f-09c7-43fd-f3e7-9b2f8ffdddb3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 1 of 1000; error is 327.58109521865845"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.42340425531914894\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 2 of 1000; error is 304.3509783744812"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.4238297872340426\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 3 of 1000; error is 297.68395042419434"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.43170212765957444\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 4 of 1000; error is 293.6111159324646"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.4521276595744681\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 5 of 1000; error is 289.06933641433716"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.4887234042553191\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 6 of 1000; error is 286.81177139282227"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.5580851063829787\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 7 of 1000; error is 283.1424021720886"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.6159574468085106\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 8 of 1000; error is 278.8053903579712"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.6551063829787234\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 9 of 1000; error is 275.8278818130493"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.6893617021276596\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 10 of 1000; error is 271.9464659690857"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.7180851063829787\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 11 of 1000; error is 269.45283460617065"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.7368085106382979\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 12 of 1000; error is 266.0232186317444"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.7597872340425532\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 13 of 1000; error is 262.9786162376404"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.7821276595744681\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 14 of 1000; error is 259.0933938026428"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.7940425531914893\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 15 of 1000; error is 256.21489429473877"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.7978723404255319\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 16 of 1000; error is 253.22943878173828"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8012765957446808\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 17 of 1000; error is 250.08966064453125"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.806595744680851\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 18 of 1000; error is 247.5758671760559"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.81\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 19 of 1000; error is 243.4214153289795"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8148936170212766\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 20 of 1000; error is 240.72919178009033"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8176595744680851\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 21 of 1000; error is 237.84553241729736"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8208510638297872\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 22 of 1000; error is 234.72047233581543"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8270212765957446\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 23 of 1000; error is 232.15978240966797"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.831063829787234\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 24 of 1000; error is 229.7706847190857"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8317021276595745\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 25 of 1000; error is 226.56119585037231"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.833404255319149\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 26 of 1000; error is 223.03620052337646"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8340425531914893\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 27 of 1000; error is 220.2443985939026"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8380851063829787\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 28 of 1000; error is 217.35300207138062"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8387234042553191\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 29 of 1000; error is 213.68365621566772"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8391489361702128\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 30 of 1000; error is 211.78592681884766"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8444680851063829\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 31 of 1000; error is 208.57571506500244/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 32 of 1000; error is 205.56649446487427"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8457446808510638\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 33 of 1000; error is 203.54917907714844"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8470212765957447\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 34 of 1000; error is 199.6723394393921"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8493617021276596\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 35 of 1000; error is 196.39367055892944/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 36 of 1000; error is 193.1368227005005"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.85\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 37 of 1000; error is 190.7714924812317"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8506382978723405\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 38 of 1000; error is 188.28508758544922/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 39 of 1000; error is 184.38945174217224/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 40 of 1000; error is 182.41417837142944"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8519148936170213\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 41 of 1000; error is 179.2466526031494"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8525531914893617\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 42 of 1000; error is 176.15759825706482/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 43 of 1000; error is 173.1499490737915/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 44 of 1000; error is 170.2132225036621/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 45 of 1000; error is 167.48974657058716/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 46 of 1000; error is 164.07598567008972/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 47 of 1000; error is 161.5401313304901"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8529787234042553\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 48 of 1000; error is 158.4403784275055"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8546808510638297\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 49 of 1000; error is 155.99926567077637/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 50 of 1000; error is 153.138671875"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.855531914893617\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 51 of 1000; error is 150.17009043693542"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8559574468085106\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 52 of 1000; error is 147.27643871307373/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 53 of 1000; error is 144.57079648971558"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8572340425531915\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 54 of 1000; error is 141.33150553703308"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8580851063829787\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 55 of 1000; error is 138.72401547431946/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 56 of 1000; error is 136.37435793876648/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 57 of 1000; error is 132.64733409881592/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 58 of 1000; error is 130.4223828315735/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 59 of 1000; error is 127.65849280357361/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 60 of 1000; error is 124.59737634658813/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 61 of 1000; error is 122.17274975776672/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 62 of 1000; error is 119.60298800468445"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8589361702127659\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 63 of 1000; error is 116.70892000198364"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Score: 0.8597872340425532\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 64 of 1000; error is 114.26966619491577/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 65 of 1000; error is 111.52819561958313/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 66 of 1000; error is 108.75630259513855/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 67 of 1000; error is 105.96496391296387/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 68 of 1000; error is 103.51529312133789/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 69 of 1000; error is 100.97032117843628/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 70 of 1000; error is 98.4324324131012/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 71 of 1000; error is 95.95126605033875/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 72 of 1000; error is 93.41570901870728/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Finished epoch 73 of 1000; error is 90.82533001899719/content/gdrive/Shareddrives/CS224U/cs224u/torch_color_describer.py:683: RuntimeWarning: divide by zero encountered in power\n","  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n","Stopping after epoch 74. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 88.4832501411438"]},{"output_type":"stream","name":"stdout","text":["CPU times: user 20min 59s, sys: 1min 36s, total: 22min 35s\n","Wall time: 22min 38s\n"]}]},{"cell_type":"code","source":["def create_bakeoff_submission(\n","        trained_model,\n","        output_filename='cs224u-colors-bakeoff-entry-glove.csv'):\n","    bakeoff_src_filename = os.path.join(\n","        \"data\", \"colors\", \"cs224u-colors-test.csv\")\n","\n","    bakeoff_corpus = ColorsCorpusReader(bakeoff_src_filename)\n","\n","    # This code just extracts the colors and texts from the new corpus:\n","    bakeoff_rawcols, bakeoff_texts = zip(*[\n","        [ex.colors, ex.contents] for ex in bakeoff_corpus.read()])\n","\n","    # Original system function call; `trained_model` is your trained model:\n","    evaluation = evaluate_original_system(\n","        trained_model, bakeoff_rawcols, bakeoff_texts)\n","\n","    evaluation['bakeoff_text'] = bakeoff_texts\n","\n","    df = pd.DataFrame(evaluation)\n","    df.to_csv(output_filename)\n","\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","    pass\n","    create_bakeoff_submission(dev_mod_glove)"],"metadata":{"id":"tCISE_tHhX7E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dev_trans.to_pickle('models/final_transformer.pkl')"],"metadata":{"id":"9emCLx7LjRZq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dev_mod_glove.to_pickle('models/final_glove.pkl')"],"metadata":{"id":"V2qvlt3YjSEs"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["5IkQF-gsCj6I","pVho4Xr-Cj6K","nyl63zoxCj6K","tAmU-R7ICj6L","3x_RWUaCCj6N","oDQmRUw4hYqs"],"name":"project_colors.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}